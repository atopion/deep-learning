{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvMa0xUr4oWJ"
   },
   "source": [
    "# VAE Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "myznXY1I-Q3d"
   },
   "source": [
    " ### GENERAL INFORMATION\n",
    " * Deep Learning – Winter term 2020/21\n",
    " * Instructor: Alexander Ecker\n",
    " * Tutors: Max Burg, Laura Pede\n",
    " * Teaching assistants: Clara Holzhüter, Pronaya Prosun Das\n",
    " * Due date: **Tue, Jan 26, 14:00**\n",
    "\n",
    "In this exercise a variational autoencoder (VAE) shall be implemented and trained on the fashion MNIST dataset. VAEs are an example of generative deep learning and can be used to synthesize data - images in this case - which shall also be demonstrated in this exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzBH5szN6dIL"
   },
   "source": [
    "### IMPORTANT SUBMISSION INSTRUCTIONS\n",
    "\n",
    "- When you're done, download the notebook and rename it to \\<surname1\\>_\\<surname2\\>_\\<surname3\\>.ipynb\n",
    "- Only submit the ipynb file, no other file is required\n",
    "- Submit only once\n",
    "- The deadline is strict\n",
    "- You are required to present your solution in the tutorial; submission of the notebook alone is not sufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N9E2cRSweAkM"
   },
   "source": [
    "### TASKS\n",
    "* TASK 1: Implement a VAE\n",
    "* TASK 2: Train the model and plot train+test set loss over training in the same plot\n",
    "* TASK 3: Determine optimal dimensionality of latent space\n",
    "* TASK 4: Plot some latent traversals\n",
    "* TASK 5: Visualize class labels in latent space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSyGC9TH5qwg"
   },
   "source": [
    "## Setup and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaX8zMh6PNq0"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "FaCNQC0aPRrs",
    "outputId": "66eb26de-b972-42ed-f2d0-2db510af6671"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "!nvcc --version\n",
    "!python --version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kX893ozpPyoV"
   },
   "source": [
    "### Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgExPcYmXZJd"
   },
   "source": [
    "Define various global parameters used throughout the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UsnqQfPcWCFU",
    "outputId": "61ef7910-325b-4753-a7f4-46679a311d0f"
   },
   "outputs": [],
   "source": [
    "# Try to use GPU if available\n",
    "use_cuda = True\n",
    "\n",
    "# Path for data\n",
    "data_dir = pathlib.Path('data/')\n",
    "\n",
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Image size (same size in both dimensions)\n",
    "image_size = 28\n",
    "\n",
    "# Dimension of the latent space\n",
    "latent_space_dim = 10\n",
    "\n",
    "# Number of epochs to train\n",
    "epochs = 5\n",
    "\n",
    "# How many batches to skip before logging training status\n",
    "log_interval = 100\n",
    "\n",
    "# Exponential averaging factor for loss graphs\n",
    "exp_average_factor = 0.90\n",
    "\n",
    "# Channels in the convolutional layers\n",
    "capacity = 32\n",
    "\n",
    "# Learning rate for the optimizer\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Define size / zoom level of plots\n",
    "plot_zoom = 2\n",
    "plot_w, plot_h = plt.figure().get_size_inches()\n",
    "plot_w = plot_w * plot_zoom; plot_h = plot_h * plot_zoom;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EB6YV4iQXXMZ"
   },
   "source": [
    "Test if a GPU (CUDA) is available in the environment and use it if it is. Otherwise use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0HWtFEuWQFFq",
    "outputId": "066b8eda-167a-4ee6-952e-9a38d8c49ec7"
   },
   "outputs": [],
   "source": [
    "if use_cuda and not torch.cuda.is_available():\n",
    "    print(\"Error: cuda requested but not available, will use cpu instead!\")\n",
    "    device = torch.device('cpu')\n",
    "elif not use_cuda:\n",
    "    print(\"Info: will use cpu!\")\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    print(\"Info: cuda requested and available, will use gpu!\")\n",
    "    device = torch.device('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--F0Vtqf-P7N"
   },
   "source": [
    "## Get and preprocess the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEsItBtJUOmS"
   },
   "source": [
    "We will use the FashionMNIST data set from Zalando (https://github.com/zalandoresearch/fashion-mnist) for our experiments.  \n",
    "From the quoted github-repo: \"Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkKBH1DfVQJr"
   },
   "source": [
    "### Load the data for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPO6AkjAITMa"
   },
   "source": [
    "The FashionMNIST dataset is already included in the torchvision datasets with the approriate training and test splits. Run the cell below to use it in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "rrtg9zz_Vjhy",
    "outputId": "3c1a3266-5b67-46be-be00-cda46e5bd313"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.FashionMNIST(data_dir, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset  = datasets.FashionMNIST(data_dir, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwQlNPQGIhuO"
   },
   "source": [
    "For comparison, you can also use the well known MNIST dataset, which is also already included in the torchvision datasets with the approriate training and test splits. Just run the cell included in the appendix instead if you want to use it in this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFhBVqsgJyz2"
   },
   "source": [
    "Define data loaders for the training and test sets which return batches of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T33MobpKvcTy"
   },
   "outputs": [],
   "source": [
    "# Define the data loaders\n",
    "train_loader  = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader   = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Save data set sizes for later\n",
    "train_size    = len(train_dataset)\n",
    "test_size     = len(test_dataset)\n",
    "train_batches = len(train_loader)\n",
    "test_batches  = len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ewL37pDOn8a2"
   },
   "source": [
    "### Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAa_6IrZC9K_"
   },
   "source": [
    "To get an impression of the dataset plot some random exemplary pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "8EAt7rLOn_zC",
    "outputId": "8d34f0dc-0ac5-41d3-f106-dc214151cea8"
   },
   "outputs": [],
   "source": [
    "images_columns = 10\n",
    "images_rows    = 6\n",
    "\n",
    "def show_grid(images_tensor, images_columns, images_rows):\n",
    "    image = torchvision.utils.make_grid(images_tensor, images_columns, images_rows)\n",
    "    image = image.numpy()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(plot_w, plot_h)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(image, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = data_iterator.next()\n",
    "\n",
    "show_grid(images[0:(images_columns * images_rows)], images_columns, images_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOJ3IzMu-inG"
   },
   "source": [
    "## Implement a convolutional Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRyKvBKU-rkh"
   },
   "source": [
    "### Implement the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8bZZMMYpYSR"
   },
   "source": [
    "Recall that a VAE roughly consistst of two parts: The encoder (which reduces the number of dimensions and maps the input to the latent space) and the decoder (which reverses the encoding, mapping from the latent space back to the initial space).\n",
    "\n",
    "\n",
    "![alt text](https://miro.medium.com/max/3148/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T67LLwDtrhN8"
   },
   "source": [
    "**TASK 1: Implement a VAE with the following network architecture**\n",
    "\n",
    "We will implement a basic convolutional VAE architecture. Look at the following VAE class template and loss function and implement the missing parts according to the following specification: \n",
    "\n",
    "**Encoder (sequential model):**\n",
    " * Convolutional Layer with (1, capacity) number of (in, out)-channels, kernel size of 4 * 4, stride of 2 and padding of 1\n",
    " * ReLU Activation Layer\n",
    " * Convolutional Layer with (capacity, 2 * capacity) number of (in, out)-channels, kernel size of 4 * 4, stride of 2 and padding of 1\n",
    " * ReLU Activation Layer\n",
    " \n",
    "**Sampling:**\n",
    "* mu, logvar: Linear Layer with 2 * capacity * 7 * 7 input features and latent_dims output features each \n",
    "* z: Linear Layer with latent_dims input features and 2 * capacity * 7 * 7 output features\n",
    "\n",
    "**Decoder (sequential model):**\n",
    " * ConvTranspose2d Layer with (2 * capacity, capacity) number of (in, out)-channels, kernel size of 4 * 4, stride of 2 and padding of 1 \n",
    " * ReLU Activation Layer\n",
    " * ConvTranspose2d Layer with (capacity, 1) number of (in, out)-channels, kernel size of 4 * 4, stride of 2 and padding of 1 \n",
    " * Sigmoid Activation Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**\n",
    "\n",
    "For the sampling use the reparameterization trick:\n",
    "\n",
    "To generate x ~ N(μ, σ²), sample ε ~ N(0, 1). Then x can be computed as x = μ + σε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4Z5nTEixKxC"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size=28, latent_dims=10, capacity=32):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_dims  = latent_dims\n",
    "        self.image_size   = image_size\n",
    "        self.capacity     = capacity\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            # TODO\n",
    "        )\n",
    "\n",
    "        # Sampling\n",
    "        self.fc_mu      = # TODO\n",
    "        self.fc_logvar  = # TODO\n",
    "        self.fc_z       = # TODO\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            # TODO\n",
    "        )\n",
    "  \n",
    "    def encode(self, x):\n",
    "        ''' Encoder: output is (mean, log(variance))'''\n",
    "        # TODO\n",
    "        return mu, logvar\n",
    "\n",
    "    def sample(self, mu, logvar):\n",
    "        ''' Sample from Gaussian with mean `mu` and SD `sqrt(exp(logvarz))`'''\n",
    "        if self.training:\n",
    "            # TODO: Reparameterization + sampling\n",
    "            return ...\n",
    "        else:\n",
    "            # During testing we don't sample but take the mean\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        '''Decoder: produces reconstruction from sample of latent z'''\n",
    "        # TODO\n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.sample(mu, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mu, logvar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1MgpHg98-zxz"
   },
   "source": [
    "### Implement the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wybNGcxHr6DG"
   },
   "source": [
    "Implement the two parts of the loss function: reconstruction loss using Mean Squared Error (MSE) function and the regularization part of the loss using Kullback-Leibler-Divergence (KLD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** Make sure that you use sum instead of mean for calculating the MSE loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXYSuDobGcsP"
   },
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    # Reconstruction losses are calculated using Mean Squared Error (MSE) and \n",
    "    # summed over all elements and batch\n",
    "    mse_loss = # TODO\n",
    "\n",
    "    # See Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    kld_loss = # TODO\n",
    "\n",
    "    total_loss = mse_loss + kld_loss\n",
    "\n",
    "    return total_loss, mse_loss, kld_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eXQvkEHHHIN"
   },
   "source": [
    "### Instantiate the model and define the optimizer to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzOxofMoHK9c"
   },
   "outputs": [],
   "source": [
    "model = # TODO\n",
    "optimizer = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ekkZCzQNEL0"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skZM-YYS_jiJ"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7-EkMvFqobc"
   },
   "source": [
    "**TASK 2: Train the model and plot train+test set loss over training in the same plot**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84mOssdQGsTY"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rt4GrpWTsW3c"
   },
   "source": [
    "### Visualization of random samples from the latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uK_R4juaDQLY"
   },
   "source": [
    "Here we create a number of random samples from the latent space and use the decoder to generate images from them. Rerun the code cell to generate new samples every time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "48PLYeOSsvQo",
    "outputId": "fc71f7c6-b17a-4528-8d41-44bd4fdb76f9"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # TODO\n",
    "    samples = ...\n",
    "\n",
    "    show_grid(samples[0:(images_columns * images_rows)], images_columns, images_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWiPxAitl0cm"
   },
   "source": [
    "### Visualization of image reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCcNbs4L9v_N"
   },
   "source": [
    "Visualize the image reconstruction process and compare to the original images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "colab_type": "code",
    "id": "o6R1ml9el-4J",
    "outputId": "68aa54fe-7c4b-48f5-d3da-155ec5dd36f4"
   },
   "outputs": [],
   "source": [
    "images_columns = 10\n",
    "images_rows    = 6\n",
    "\n",
    "data_iterator = iter(train_loader)\n",
    "images, labels = data_iterator.next()\n",
    "\n",
    "# Show original images\n",
    "show_grid(images[0:(images_columns * images_rows)], images_columns, images_rows)\n",
    "\n",
    "# Show reconstructed images\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    # TODO: compute reconstruction\n",
    "    images_recon = ...\n",
    "\n",
    "    show_grid(images_recon[0:(images_columns * images_rows)], images_columns, images_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZtUdOloR4z2"
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6btKzA8RzVK"
   },
   "source": [
    "**TASK 3: Explore dimensionality of latent space**\n",
    "\n",
    "How does the dimensionality of latent space (set to 10 by default in our case) affect loss and quality of the reconstructions? Explore smaller and larger latent dimensionality by using 2, 4, 8, 16, 32 dimensions and looking at reconstructions and resulting test set loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vp-F4FPsAtxN"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QB--L53dJX0"
   },
   "source": [
    "## Visualization of latent traversals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04i1OlkTTMBs"
   },
   "source": [
    "**TASK 4: Plot some latent traversals**\n",
    "\n",
    "Latent traversal is a popular approach to visualize the disentangled latent representations. Given a bunch of variations in a single unit of the latent representation, it is expected that there is a change in a single factor of variation of the data while others are fixed. \n",
    "[https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550681.pdf]\n",
    "\n",
    "Create a 10 x 10 matrix plot showing latent space travels by selecting vectors from latent space and using the decoder part of the VAE neural network to create images from them. \n",
    "\n",
    "**TODO**\n",
    "- select two separate latent space dimensions of the vector, e.g. axi=1, axj=9\n",
    "- create a vector with of size *latent_space_dim* containing zeros\n",
    "- traverse the latent space dimensions from -3 to 3 in 10 steps, each time setting the value of the vector at axi and axj to the current traversed value\n",
    "- use the decoder to create the corresponding image and plot it\n",
    "- repeat the experiment, now setting the other dimensions of the vector to a random value in [-1,1] instead of zero.\n",
    "\n",
    "An example is shown here: \n",
    "\n",
    "![10x10 traversal of two latent dimensions](https://i.imgur.com/hZXIYzv.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrVVH9VX4kxN"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O8UkfqvMdaPx"
   },
   "source": [
    "### Visualize class labels in latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXTs7humzfFJ"
   },
   "source": [
    "**TASK 5: Visualize class labels in latent space**\n",
    "\n",
    "First create a new VAE-model with a 2d latent space on the full training data set. Then project all the images of the training set into the 2d latent space keeping track of their class labels. Use a 2d scatter plot to visualize the resulting latent space vectors and different colors for their labels. \n",
    "\n",
    "- Do images of the same class cluster in latent space?\n",
    "- Do the data points in latent space look like a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 2d latent space model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoY6mExK3DJE"
   },
   "source": [
    "#### Visualize classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtLXiXC_8VeX"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PdEWFl_0_dKc"
   },
   "source": [
    "## Appendix [OPTIONAL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhhFQYAuczK_"
   },
   "source": [
    "Use standard MNIST or CIFAR-10 instead of fashion MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "IfzNWP0JekgF",
    "outputId": "231d34b4-fc8b-4106-9f32-1c7ec1841a02"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([ \n",
    "#                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "#                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "\n",
    "train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(data_dir, train=False, transform=transforms.ToTensor())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE-Exercise-TODO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
